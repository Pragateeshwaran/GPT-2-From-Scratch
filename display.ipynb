{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "sample 0: \n",
      "Money is the root of all evil to a man as you do.<|endoftext|>As a bit of a second, when you say, The P:S. So I Am Allocation\n",
      "\n",
      "And-\n",
      "\n",
      "The 4, you've a lot of the \"sail\" the \"hoor\"\n",
      "\n",
      "In the late 1980\n",
      "\n",
      "It, the most years\n",
      "\n",
      "\n",
      "In a one-seasonly-in-one, it shouldy, is a four-body-\n",
      "\n",
      "When the two-managing for men, the more, I've the back and you are in. It is too. The \"Hem-\n",
      "\n",
      "\n",
      "sample 1: \n",
      "Money is the root of all evil. You may also, what's in the house-holding. It's not just a bad idea of your face-in-the-nour-as-it's-it, and by the body of your body-at-you-you-you-happing-your-in-you-they, you be- you might in the face of your face, who is in-onion that's-what are you, the the rest of the-body is a bad-body is your work, right-up. Why do you say this mayor (em-\n",
      "\n",
      "\n",
      "sample 2: \n",
      "Money is the root of all evil. I'm a bit of a day after the future of the car, it's the best of a bit.\n",
      "\n",
      "The more that you will have the \"lone-all\" - and a year.\n",
      "\n",
      "\"If You Go Round Your Business, You've Been Made.\n",
      "\n",
      "This is an \"in-soul of a certain moment\" (1, 3 months, as in the past. How amo, that's a problem, why one day was 1 minute.\n",
      "\n",
      "For a little-one on this post\n",
      "\n",
      "Wif, they've got to read this\n",
      "\n",
      "\n",
      "sample 3: \n",
      "Money is the root of all evil should you take that, and that's a-magnating a bad-time is in one way, to be more that. It's an exorbitant. It may be the \"The New 'em.\"\n",
      "\n",
      "\n",
      "\"Sheik is the first to your eyes. It's all the like, the only way that you may be the business of the past 5-2 have, there's the body that's the body can be at least. \"Do you keep the game. It's all, a: \"The \"I want to be the next season, as-you-you\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from transformers import GPT2Tokenizer\n",
    "from main import NeuroFill, NeuroFillConfig\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.nn import functional as F\n",
    "\n",
    "neurofill_config = NeuroFillConfig()\n",
    "neurofill_model = NeuroFill(neurofill_config)\n",
    "enc = GPT2Tokenizer.from_pretrained('gpt2') \n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "neurofill_model.load_state_dict(torch.load('model_20000.pth'))\n",
    "model = neurofill_model.to(device)\n",
    "\n",
    "model.eval()\n",
    "num_return_sequences = 4\n",
    "max_length = 128\n",
    "text = \"Money is the root of all evil\"\n",
    "tokens = enc.encode(text)\n",
    "tokens = torch.tensor(tokens, dtype=torch.long)\n",
    "tokens = tokens.unsqueeze(0).repeat(num_return_sequences, 1)\n",
    "xgen = tokens.to(device)\n",
    "sample_rng = torch.Generator(device=device)\n",
    "while xgen.size(1) < max_length:\n",
    "    with torch.no_grad():\n",
    "        # with torch.autocast(device_type=device, dtype=torch.bfloat16):\n",
    "        logits, _ = model(xgen)\n",
    "        logits = logits[:, -1, :]\n",
    "        probs = F.softmax(logits, dim=-1)\n",
    "        topk_probs, topk_indices = torch.topk(probs, 50, dim=-1)\n",
    "        ix = torch.multinomial(topk_probs, 1, generator=sample_rng)\n",
    "        xcol = torch.gather(topk_indices, -1, ix)\n",
    "        xgen = torch.cat((xgen, xcol), dim=1)\n",
    "for i in range(num_return_sequences):\n",
    "    tokens = xgen[i, :max_length].tolist()\n",
    "    decoded = enc.decode(tokens)\n",
    "    print(f\"\\nsample {i}: \\n{decoded}\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "NeuroFill(\n",
       "  (transformer): ModuleDict(\n",
       "    (wte): Embedding(50257, 768)\n",
       "    (wpe): Embedding(1024, 768)\n",
       "    (h): ModuleList(\n",
       "      (0-11): 12 x BLOCK(\n",
       "        (ln_1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "        (attn): AttentionNet(\n",
       "          (c_attn): Linear(in_features=768, out_features=2304, bias=True)\n",
       "          (c_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "        )\n",
       "        (ln_2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "        (mlp): MLP(\n",
       "          (c_fc): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (gelu): GELU(approximate='tanh')\n",
       "          (c_proj): Linear(in_features=3072, out_features=768, bias=True)\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "    (ln_f): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "  )\n",
       "  (lm_head): Linear(in_features=768, out_features=50257, bias=False)\n",
       ")"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "neurofill_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
